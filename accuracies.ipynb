{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from medpy.io import load\n",
    "from skimage.measure import block_reduce\n",
    "import scipy\n",
    "import os\n",
    "import seaborn as sns\n",
    "import nibabel as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input_resnet = tf.keras.applications.resnet.preprocess_input\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    arr = arr + abs(np.amin(arr))\n",
    "    assert np.amax(arr) != 0\n",
    "    arr = arr / np.amax(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "name = []\n",
    "\n",
    "for i in range(500):\n",
    "    try :\n",
    "        t1 = sitk.ReadImage(os.getcwd() + \"/Data/FA\" + str(1000+i) + \".nii\")\n",
    "        t2 = sitk.GetArrayFromImage(t1)\n",
    "        t3 = []\n",
    "        for j in range(0,90):\n",
    "            result = scipy.ndimage.zoom(t2[j], 224/288)\n",
    "            t3.append(result)\n",
    "        X.append(t3)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "for i in range(500):\n",
    "    try :\n",
    "        t1 = sitk.ReadImage(os.getcwd() + \"/Data/FA\" + str(2000+i) + \".nii\")\n",
    "        t2 = sitk.GetArrayFromImage(t1)\n",
    "        t3 = []\n",
    "        for j in range(0,90):\n",
    "            result = scipy.ndimage.zoom(t2[j], 224/288)\n",
    "            t3.append(result)\n",
    "        X.append(t3)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(len(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "# 2\n",
    "# (72, 40, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 90, 85, 71) (20, 90, 85, 71) (44,) (20,)\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate(( [0]*34, [1]*30 ))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=34)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1760, 85, 71) (1760,) (800, 85, 71) (800,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.resize(X_train, ((40*44), 85, 71))\n",
    "X_test = np.resize(X_test, ((40*20), 85, 71))\n",
    "\n",
    "temp_y_train = np.array([])\n",
    "for i in range(len(y_train)):\n",
    "    for j in range(40):\n",
    "        temp_y_train = np.append(temp_y_train, y_train[i])\n",
    "\n",
    "temp_y_test = np.array([])\n",
    "for i in range(len(y_test)):\n",
    "    for j in range(40):\n",
    "        temp_y_test = np.append(temp_y_test, y_test[i])\n",
    "\n",
    "y_train = temp_y_train\n",
    "y_test = temp_y_test\n",
    "\n",
    "print(np.shape(X_train), np.shape(y_train), np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_RGB = np.stack((X_train,)*3, axis=-1)\n",
    "\n",
    "X_test_RGB = np.stack((X_test,)*3, axis=-1)\n",
    "\n",
    "train_ds = preprocess_input_resnet(X_train_RGB)\n",
    "test_ds = preprocess_input_resnet(X_test_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 3s - loss: 0.6879 - accuracy: 0.5500 - 3s/epoch - 114ms/step\n",
      "Restored model, accuracy: 55.00%\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('ResNet50/RESNET_ocd_resting_state_dataset_t1_2d.h5')\n",
    "loss, acc = new_model.evaluate(test_ds, y_test, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "name = []\n",
    "\n",
    "for i in range(500):\n",
    "    try :\n",
    "        t1 = sitk.ReadImage(\"./Data/FA\" + str(1000+i) + \".nii\")\n",
    "        t2 = sitk.GetArrayFromImage(t1)\n",
    "        t3 = []\n",
    "        for j in range(0,90):\n",
    "            result = scipy.ndimage.zoom(t2[j], 224/288)\n",
    "            t3.append(result)\n",
    "        X.append(t3)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "for i in range(500):\n",
    "    try :\n",
    "        t1 = sitk.ReadImage(\"./Data/FA\" + str(2000+i) + \".nii\")\n",
    "        t2 = sitk.GetArrayFromImage(t1)\n",
    "        t3 = []\n",
    "        for j in range(0,90):\n",
    "            result = scipy.ndimage.zoom(t2[j], 224/288)\n",
    "            t3.append(result)\n",
    "        X.append(t3)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 90, 85, 71) (20, 90, 85, 71) (44,) (20,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "\n",
    "y = np.concatenate(( [0]*34, [1]*30 ))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=34)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1760, 85, 71) (1760,) (800, 85, 71) (800,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.resize(X_train, ((40*44), 85, 71))\n",
    "X_test = np.resize(X_test, ((40*20), 85, 71))\n",
    "\n",
    "temp_y_train = np.array([])\n",
    "for i in range(len(y_train)):\n",
    "    for j in range(40):\n",
    "        temp_y_train = np.append(temp_y_train, y_train[i])\n",
    "\n",
    "temp_y_test = np.array([])\n",
    "for i in range(len(y_test)):\n",
    "    for j in range(40):\n",
    "        temp_y_test = np.append(temp_y_test, y_test[i])\n",
    "\n",
    "y_train = temp_y_train\n",
    "y_test = temp_y_test\n",
    "\n",
    "print(np.shape(X_train), np.shape(y_train), np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 4.4628 - accuracy: 0.5050 - 305ms/epoch - 12ms/step\n",
      "Restored model, accuracy: 50.50%\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('Novel/NOVEL_ocd_resting_state_dataset_t1_2d.h5')\n",
    "loss, acc = new_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
